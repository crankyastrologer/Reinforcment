{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import operator\n",
    "from IPython.display import clear_output\n",
    "from time import sleep\n",
    "import random\n",
    "import itertools\n",
    "import tqdm\n",
    "tqdm.monitor_interval = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "def create_random_policy(env):\n",
    "    policy = {}\n",
    "    for key in range(0,env.observation_space.n):\n",
    "        current_end = 0\n",
    "        p = {}\n",
    "        for action in range(0,env.action_space.n):\n",
    "            p[action] = 1/env.action_space.n\n",
    "            policy[key] = p\n",
    "    return policy\n",
    "\n",
    "def create_state_action_dictionary(env,policy):\n",
    "    Q = {}\n",
    "    for key in policy.keys():\n",
    "        Q[key] = {a: 0.0 for a in range(0,env.action_space.n)}\n",
    "    return Q\n",
    "\n",
    "def run_game(env,policy,display = True):\n",
    "    env.reset()\n",
    "    episode = []\n",
    "    finished = False\n",
    "\n",
    "    while not finished:\n",
    "        s = env.env.s\n",
    "        if display:\n",
    "            clear_output(True)\n",
    "            env.render()\n",
    "            sleep(1)\n",
    "        timestep = [s]\n",
    "        n = random.uniform(0,sum(policy[s].values()))\n",
    "        top_range = 0\n",
    "        for prob in policy[s].items():\n",
    "            top_range +=prob[1]\n",
    "            if n<top_range:\n",
    "                action =  prob[0]\n",
    "\n",
    "                break\n",
    "\n",
    "        state, reward, finished, info, abc = env.step(action)\n",
    "        timestep.append(action)\n",
    "        timestep.append(reward)\n",
    "        episode.append(timestep)\n",
    "        if display:\n",
    "          clear_output(True)\n",
    "          env.render()\n",
    "          sleep(1)\n",
    "\n",
    "    return episode\n",
    "def test_policy(policy,env):\n",
    "    wins = 0\n",
    "    r = 100\n",
    "    for i in range(r):\n",
    "        print(f'doing {i}')\n",
    "        w = run_game(env,policy,display=False)[-1][-1]\n",
    "        if w == 1:\n",
    "            wins+=1\n",
    "    return wins / r"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "def monte_carlo_e_soft(env,episodes=10000,policy=None,epsilon=0.01):\n",
    "    if not policy:\n",
    "        policy = create_random_policy(env)\n",
    "    Q = create_state_action_dictionary(env,policy)\n",
    "    returns = {}\n",
    "    for _ in range(episodes):\n",
    "\n",
    "        G = 0\n",
    "        episode = run_game(env = env,policy=policy, display=False)\n",
    "        for i in reversed(range(0,len(episode))):\n",
    "            s_t,a_t,r_t = episode[i]\n",
    "            state_action = (s_t, a_t)\n",
    "            G += r_t\n",
    "            if not state_action in [(x[0], x[1]) for x in episode[0:i]]:\n",
    "                if returns.get(state_action):\n",
    "                    returns[state_action].append(G)\n",
    "                else:\n",
    "                    returns[state_action]=[G]\n",
    "\n",
    "                Q[s_t][a_t] = sum(returns[state_action])/len(returns[state_action])\n",
    "\n",
    "                Q_list = list(map(lambda x: x[1], Q[s_t].items()))\n",
    "                indices = [i for i, x in enumerate(Q_list) if x== max(Q_list)]\n",
    "                max_Q = random.choice(indices)\n",
    "                A_star = max_Q\n",
    "                for a in policy[s_t].items():\n",
    "                    if a[0]==A_star:\n",
    "                        policy[s_t][a[0]] = 1\n",
    "                    else:\n",
    "                        policy[s_t][a[0]] = 0\n",
    "\n",
    "    return policy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing 0\n",
      "doing 1\n",
      "doing 2\n",
      "doing 3\n",
      "doing 4\n",
      "doing 5\n",
      "doing 6\n",
      "doing 7\n",
      "doing 8\n",
      "doing 9\n",
      "doing 10\n",
      "doing 11\n",
      "doing 12\n",
      "doing 13\n",
      "doing 14\n",
      "doing 15\n",
      "doing 16\n",
      "doing 17\n",
      "doing 18\n",
      "doing 19\n",
      "doing 20\n",
      "doing 21\n",
      "doing 22\n",
      "doing 23\n",
      "doing 24\n",
      "doing 25\n",
      "doing 26\n",
      "doing 27\n",
      "doing 28\n",
      "doing 29\n",
      "doing 30\n",
      "doing 31\n",
      "doing 32\n",
      "doing 33\n",
      "doing 34\n",
      "doing 35\n",
      "doing 36\n",
      "doing 37\n",
      "doing 38\n",
      "doing 39\n",
      "doing 40\n",
      "doing 41\n",
      "doing 42\n",
      "doing 43\n",
      "doing 44\n",
      "doing 45\n",
      "doing 46\n",
      "doing 47\n",
      "doing 48\n",
      "doing 49\n",
      "doing 50\n",
      "doing 51\n",
      "doing 52\n",
      "doing 53\n",
      "doing 54\n",
      "doing 55\n",
      "doing 56\n",
      "doing 57\n",
      "doing 58\n",
      "doing 59\n",
      "doing 60\n",
      "doing 61\n",
      "doing 62\n",
      "doing 63\n",
      "doing 64\n",
      "doing 65\n",
      "doing 66\n",
      "doing 67\n",
      "doing 68\n",
      "doing 69\n",
      "doing 70\n",
      "doing 71\n",
      "doing 72\n",
      "doing 73\n",
      "doing 74\n",
      "doing 75\n",
      "doing 76\n",
      "doing 77\n",
      "doing 78\n",
      "doing 79\n",
      "doing 80\n",
      "doing 81\n",
      "doing 82\n",
      "doing 83\n",
      "doing 84\n",
      "doing 85\n",
      "doing 86\n",
      "doing 87\n",
      "doing 88\n",
      "doing 89\n",
      "doing 90\n",
      "doing 91\n",
      "doing 92\n",
      "doing 93\n",
      "doing 94\n",
      "doing 95\n",
      "doing 96\n",
      "doing 97\n",
      "doing 98\n",
      "doing 99\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('FrozenLake-v1', desc=None, map_name=\"4x4\", render_mode = 'rgb_array')\n",
    "policy = monte_carlo_e_soft(env)\n",
    "a = test_policy(policy,env)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {0: 0, 1: 1, 2: 0, 3: 0}, 1: {0: 0, 1: 0, 2: 1, 3: 0}, 2: {0: 1, 1: 0, 2: 0, 3: 0}, 3: {0: 0, 1: 1, 2: 0, 3: 0}, 4: {0: 0, 1: 0, 2: 1, 3: 0}, 5: {0: 0.25, 1: 0.25, 2: 0.25, 3: 0.25}, 6: {0: 0, 1: 0, 2: 1, 3: 0}, 7: {0: 0.25, 1: 0.25, 2: 0.25, 3: 0.25}, 8: {0: 1, 1: 0, 2: 0, 3: 0}, 9: {0: 1, 1: 0, 2: 0, 3: 0}, 10: {0: 0, 1: 1, 2: 0, 3: 0}, 11: {0: 0.25, 1: 0.25, 2: 0.25, 3: 0.25}, 12: {0: 0.25, 1: 0.25, 2: 0.25, 3: 0.25}, 13: {0: 0, 1: 0, 2: 1, 3: 0}, 14: {0: 0, 1: 0, 2: 1, 3: 0}, 15: {0: 0.25, 1: 0.25, 2: 0.25, 3: 0.25}}\n"
     ]
    }
   ],
   "source": [
    "print(policy)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym[toy_text] in c:\\users\\ansh0\\anaconda3\\envs\\portfolio\\lib\\site-packages (0.26.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\ansh0\\anaconda3\\envs\\portfolio\\lib\\site-packages (from gym[toy_text]) (2.2.1)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in c:\\users\\ansh0\\anaconda3\\envs\\portfolio\\lib\\site-packages (from gym[toy_text]) (0.0.8)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\ansh0\\anaconda3\\envs\\portfolio\\lib\\site-packages (from gym[toy_text]) (6.6.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\ansh0\\anaconda3\\envs\\portfolio\\lib\\site-packages (from gym[toy_text]) (1.23.5)\n",
      "Collecting pygame==2.1.0\n",
      "  Downloading pygame-2.1.0-cp38-cp38-win_amd64.whl (4.8 MB)\n",
      "     ---------------------------------------- 4.8/4.8 MB 2.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\ansh0\\anaconda3\\envs\\portfolio\\lib\\site-packages (from importlib-metadata>=4.8.0->gym[toy_text]) (3.11.0)\n",
      "Installing collected packages: pygame\n",
      "Successfully installed pygame-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gym[toy_text]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import operator\n",
    "from IPython.display import clear_output\n",
    "from time import sleep\n",
    "import random\n",
    "import itertools\n",
    "import tqdm\n",
    "\n",
    "tqdm.monitor_interval = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def create_random_policy(env):\n",
    "     policy = {}\n",
    "     for key in range(0, env.observation_space.n):\n",
    "          current_end = 0\n",
    "          p = {}\n",
    "          for action in range(0, env.action_space.n):\n",
    "               p[action] = 1 / env.action_space.n\n",
    "          policy[key] = p\n",
    "     return policy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def create_state_action_dictionary(env, policy):\n",
    "    Q = {}\n",
    "    for key in policy.keys():\n",
    "         Q[key] = {a: 0.0 for a in range(0, env.action_space.n)}\n",
    "    return Q"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
